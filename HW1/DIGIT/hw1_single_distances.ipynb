{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as ts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = int(28)            # This is the width and height of the square image, in pixels. The area of image is m*m pixels. \n",
    "\n",
    "# Part 1.a\n",
    "\n",
    "# Open data (labels and features as \"train\")\n",
    "with open ('train.csv') as train:\n",
    "            \n",
    "            train = np.array (train.readlines()[0:])\n",
    "            \n",
    "            # These three lines are condensed below comma separated values\n",
    "            labels_tr_list = [i.split(',') for i in train]\n",
    "            \n",
    "            # Take all datapoints (labels AND features) for which the label is either a zero or a one (to solve part e of Problem 1)\n",
    "            binary_data = np.array([i for i in labels_tr_list[1:] if i[0]=='0' or i[0]=='1'],dtype=np.float)\n",
    "            \n",
    "            # picks the labels/classes and put to a list\n",
    "            labels_tr_list = [int(i[0]) for i in labels_tr_list[1:]]\n",
    "            \n",
    "            \n",
    "            features_train = np.array([i.split(',') for i in train])  \n",
    "            # m x m reshapeing th e feature set\n",
    "            features_train = [np.reshape(i,(m,m)) for i in features_train[1:,1:]]\n",
    "            \n",
    "            # make sure every element is a floating point\n",
    "            features_train = np.array(features_train,dtype=np.float)\n",
    "            \n",
    "        \n",
    "            labels_train = features_train[1:,0]\n",
    "            \n",
    "#The three lines above, condensed:\n",
    "#a = np.array([np.reshape(i,(28,28)) for i in (np.array([i.split(',') for i in train]))[1:,1:]],dtype=np.float)            \n",
    "\n",
    "# # Part 1.b\n",
    "\n",
    "found = []\n",
    "found_ind = []\n",
    "for i,j in enumerate(labels_tr_list):\n",
    "    if j not in found:\n",
    "#         plt.imshow(features_train[i], cmap='hot', interpolation='nearest')\n",
    "#         plt.show()\n",
    "        found.append(j)\n",
    "        found_ind.append(i)\n",
    "        \n",
    "# Part 1.c \n",
    "\n",
    "# Creates histogram object based on the labels contained in the array \"labels_tr_list\". desity argument is used\n",
    "# to normalize de histogram.\n",
    "# plt.hist(labels_tr_list,bins = np.linspace(0,10,11),density=True)\n",
    "\n",
    "# Add title to histogram\n",
    "# plt.title(\"Frequency Distribution of Digits\") \n",
    "\n",
    "# Show histogram\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Part 1.d\n",
    "\n",
    "eucl_dists = np.empty([len(found), len(features_train),1], dtype=int)\n",
    "for j,p in enumerate(found_ind):\n",
    "    for i,k in enumerate(features_train):\n",
    "        eucl_dists[j,i]= np.dot(np.reshape(features_train[p] - features_train[i],(1,m*m))  ,  np.transpose(np.reshape(features_train[p] - features_train[i],(1,m*m))))\n",
    "        if eucl_dists[j,i] == 0:\n",
    "            eucl_dists[j,i] = 1000000000\n",
    "    min_index = np.argmin(eucl_dists[j])   \n",
    "#     if labels_tr_list[p] != labels_tr_list[min_index]:\n",
    "#         print(\"The Nearest Neighbor (L2) Distance is\",str(eucl_dists[j,i]**.5).lstrip('[').rstrip(']'),\"*\")\n",
    "#     else: \n",
    "#         print(\"The Nearest Neighbor (L2) Distance is\",str(eucl_dists[j,i]**.5).lstrip('[').rstrip(']'))\n",
    "#     plt.imshow(features_train[p], cmap='hot', interpolation='nearest')\n",
    "#     plt.show()\n",
    "#     plt.imshow(features_train[np.argmin(eucl_dists[j])], cmap='hot', interpolation='nearest')\n",
    "#     plt.show()\n",
    "    \n",
    "# Part 1.e Consider the case of binary comparison between the digits 0 and 1. Ignoring all the other\n",
    "# digits, compute the pairwise distances for all genuine matches and all impostor matches,\n",
    "# again using the L2 norm. Plot histograms of the genuine and impostor distances on the same\n",
    "# set of axes.\n",
    "\n",
    "# Create empty array to hold eucledian distances for observations with labels that are either\n",
    "# a zero (0) or one (1).\n",
    "\n",
    "\n",
    "# This represents the number of unique distances. It can be computed as the number of unique\n",
    "# pair combinations given n objets = n!/((n-2)!*2!). However, that just simplifies to the expression\n",
    "# shown below for simplicity.\n",
    "dist_count = int((len(binary_data))*(len(binary_data)-1)  /  2) \n",
    "\n",
    "# Create empty array of size dist_count (the total number of unique distances) by 2.\n",
    "bin_eucl_dists = np.empty([dist_count,2], dtype=int)\n",
    "\n",
    "# Dummy variable to index what element of bin_eucl_dists we write to (see nested loops below).\n",
    "a = 0\n",
    "\n",
    "\n",
    "# Nested for loops to populate \"bin_eucl_dists\" array (created above) with two values:\n",
    "\n",
    "# Value bin_eucl_dists[i,0] is the Eucledian Distance between two feature vectors. Note that we take the square root\n",
    "# of the inner product to get the Eucledian Distance.\n",
    "\n",
    "# Value bin_eucl_dists[i,1] is a Boolean value (0,1) representing whether these two elements are in fact matches.\n",
    "\n",
    "#print(binary_data)\n",
    "for i1,j1 in enumerate(binary_data):\n",
    "    \n",
    "    # If you have n distances, the nth distance will be compared iteratively with distances d_0 through distance\n",
    "    # d_n-1. Hence, we say below that i1 must remain < dist_count, allowing dist_count - 1 iterations. \n",
    "    if i1 < dist_count: \n",
    "        for i2,j2 in enumerate(binary_data[i1+1:]):\n",
    "            # Here, we index vector j1 and j2 from column 1 to : because column 0 is just the label, \n",
    "            # not to be included in the vector difference computation.\n",
    "            \n",
    "            bin_eucl_dists[a,0],bin_eucl_dists[a,1] = (np.dot(j1[1:]-j2[1:],np.transpose(j1[1:]-j2[1:])))**.5, j1[0]==j2[0]\n",
    "            a +=1\n",
    "    \n",
    "\n",
    "# Count the number of zero and one labels in binary_data\n",
    "len_ones = len([i for i in binary_data if i[0]==1])\n",
    "len_zeros = len([i for i in binary_data if i[0]==0])\n",
    "\n",
    "# Boolean operation to test that all elements in binary_data (zero and one labels) have been captured.\n",
    "print (len_ones + len_zeros == len(binary_data))\n",
    "\n",
    "# Extract genuine matches from bin_eucl_dists based in matching of labels in nested loops above this line.\n",
    "genuine_match = [j[0] for j in bin_eucl_dists if j[1]==1]\n",
    "false_match = [j[0] for j in bin_eucl_dists if j[1]==0]\n",
    "\n",
    "# bin1 = np.linspace(0,4000,50)\n",
    "# print(bin1)\n",
    "# Create histograms for genuine and impostor matches\n",
    "#_ = plt.hist(genuine_match, bins=\"auto\",label=\"Genuine Matches\")  # arguments are passed to np.histogram\n",
    "#_ = plt.hist(false_match, bins=\"auto\", label=\"Impostor Matches\", fc =(.2,.2,.5), alpha=.5)  # arguments are passed to np.histogram\n",
    "#plt.title(\"Histogram of Genuine and Impostor Matches\")\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "#plt.show()\n",
    "\n",
    "g_hist = np.histogram(genuine_match, bins=\"auto\")\n",
    "i_hist = np.histogram(false_match, bins=\"auto\")\n",
    "\n",
    "# Part 1.f Generate an ROC curve from the above sets of distances. What is the equal error rate? What\n",
    "# is the error rate of a classifier that simply guesses randomly?\n",
    "\n",
    "ROC_x = []\n",
    "ROC_y = []\n",
    "\n",
    "sort_bin_eucl_dists = bin_eucl_dists[bin_eucl_dists[:, 0].argsort()]\n",
    "\n",
    "for i,j in enumerate(sort_bin_eucl_dists):\n",
    "    if j[1]==1:\n",
    "        if i == 0:\n",
    "            ROC_x.append(0)\n",
    "            x_last = 0\n",
    "            ROC_y.append(1/len(genuine_match))\n",
    "            y_last = 1/len(genuine_match)\n",
    "        else:\n",
    "            ROC_x.append(x_last)\n",
    "            ROC_y.append(y_last + 1/len(genuine_match))\n",
    "            y_last = y_last + 1/len(genuine_match)\n",
    "    else:\n",
    "        if i == 0:\n",
    "            ROC_y.append(0)\n",
    "            y_last = 0\n",
    "            ROC_x.append(1/len(false_match))\n",
    "            x_last = 1/len(false_match)\n",
    "        else:\n",
    "            ROC_y.append(y_last)\n",
    "            ROC_x.append(x_last+ 1/len(false_match))   \n",
    "            x_last = x_last+ 1/len(false_match)\n",
    "\n",
    "#print(ROC_y)\n",
    "# Create two dimensional empty array to hold X and Y values of ROC Curve\n",
    "ROC_comb = np.empty([len(ROC_y),2])\n",
    "\n",
    "# Store X and Y values of ROC Curve in Array\n",
    "for i,j in enumerate(ROC_comb):\n",
    "    j[0], j[1] = ROC_x[i],ROC_y[i]\n",
    "\n",
    "# Extract points of the ROC curve where slope passes through Equal Error Rate.\n",
    "# I just looked at the ROC graph and saw that it happens somewhere prior to Y = 0.8\n",
    "# which corresponds to these indexes: Start at the 33th percentile (100/3), end at 57th\n",
    "# percentile (100/1.75).\n",
    "\n",
    "\n",
    "low_ind = int(len(ROC_comb)/2.8)\n",
    "high_ind = int(len(ROC_comb)/1.8)\n",
    "ROC_for_EER = ROC_comb[low_ind:high_ind]\n",
    "\n",
    "# Define degre of polynomial fit\n",
    "n1 = 4\n",
    "# Fit ROC_for_EER using \"n1\" degree polynomial (Array Form)\n",
    "z1 = np.polyfit(ROC_for_EER[:,0],ROC_for_EER[:,1],n1)\n",
    "# Take Array Form polynomial and turn into function\n",
    "p1 = np.poly1d(z1)\n",
    "print(p1)\n",
    "\n",
    "z2 = np.polyfit([0,1],[1,0],1)\n",
    "z2 = [0,0,0,z2[0],z2[1]]\n",
    "p2 = np.poly1d(z2)\n",
    "print(p2)\n",
    "#print(z1-z2)\n",
    "EER = np.roots(z1-z2)\n",
    "\n",
    "print(\"The false positive rate equals the false negative rate when the rates equal\", np.real(EER[3]))\n",
    "\n",
    "\n",
    "# Print the index of the element of ROC_for_EER that results in a slope closest to 1/2**.5\n",
    "#print(ROC_for_EER[delta_der_p2.argmin(0),1])\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "#ax2.set_aspect('equal', 'box')\n",
    "ax2.plot(ROC_x,ROC_y)\n",
    "\n",
    "ax2.plot(ROC_for_EER[:,0],p1(ROC_for_EER[:,0]))\n",
    "ax2.plot(ROC_for_EER[:,0],p2(ROC_for_EER[:,0]))\n",
    "\n",
    "# What is the error rate (E_random) of a classifier that simply guesses randomly? Answer = 0.5\n",
    "# Rationale is below.\n",
    "# E_random = P(Match)*P(Prediction = Match) + P(Not_Match)*P(Prediction = Not_Match) (Equation 1)\n",
    "# P(Prediction = Match) = P(Prediction = Not_Match) = 0.5 = 1/num_of_classes (i.e. we're naively guessing)\n",
    "# Also, P(Not_Match) = 1 - P(Match)\n",
    "# Hence, Equation 1 becomes: E_random = (P(Match) + 1 - P(Match)) * 0.5 = 1 * 0.5 = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ROC_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
