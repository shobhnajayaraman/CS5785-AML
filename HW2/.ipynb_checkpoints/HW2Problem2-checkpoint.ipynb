{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first demo json train data:\n",
      "{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n",
      "Number of samples is : 39774\n",
      "Number of cuisines is 20\n",
      "Sum of ingredients: 428275\n",
      "Number of unique ingredients: 6714\n"
     ]
    }
   ],
   "source": [
    "# Part 2B\n",
    "import json\n",
    "with open(\"train.json\", \"r\") as trainfile:\n",
    "    train_json_data = json.load(trainfile)\n",
    "\n",
    "print(\"This is the first demo json train data:\")\n",
    "print(train_json_data[0])\n",
    "\n",
    "cuisine_id = [] # will store the id of of the cuisine\n",
    "cuisine_type = [] # will store the cuisine type\n",
    "ingredient = [] # will store the ingredient set\n",
    "unique_ingred = []\n",
    "\n",
    "cuisine_id, cuisine_type, ingredient = [], [], []\n",
    "for tjd in train_json_data:\n",
    "    cuisine_id.append(tjd[\"id\"])\n",
    "    cuisine_type.append(tjd[\"cuisine\"])\n",
    "    ingredient.extend(tjd[\"ingredients\"])\n",
    "\n",
    "print(\"Number of samples is : {}\".format(len(cuisine_id)))\n",
    "print(\"Number of cuisines is {}\".format(len(set(cuisine_type))))\n",
    "print(\"Sum of ingredients: {}\".format(len(ingredient)))\n",
    "\n",
    "unique_ingred = set(ingredient) #this list contains the unique ingredient list\n",
    "print(\"Number of unique ingredients: {}\".format(len(unique_ingred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2C\n",
    "import numpy as np\n",
    "ing = {}\n",
    "count = 0\n",
    "for c in unique_ingred:\n",
    "    ing[c] = count\n",
    "    count = count + 1\n",
    "\n",
    "train_data = []\n",
    "for data in train_json_data:\n",
    "    appears = [0] * len(unique_ingred)\n",
    "    for i in data[\"ingredients\"]:\n",
    "        appears[ing[i]] = 1\n",
    "    train_data.append(appears)\n",
    "\n",
    "train_data = np.array(train_data, dtype=int)\n",
    "train_labels = np.array(cuisine_type, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GaussianNB()\n",
    "bn = BernoulliNB()\n",
    "multNB_clf = MultinomialNB()\n",
    "\n",
    "fold = 3\n",
    "kf = KFold(n_splits=3)\n",
    "avg_G, avg_B, avg_M = 0, 0, 0\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    \n",
    "    X_train, X_test = train_data[train_index], train_data[test_index]\n",
    "    Y_train, Y_test = train_labels[train_index], train_labels[test_index]\n",
    "    \n",
    "    gs_clf.fit(X_train, Y_train)\n",
    "    bn.fit(X_train, Y_train)\n",
    "    multNB_clf.fit(X_train, Y_train)\n",
    "    \n",
    "    avg_G = avg_G + gs_clf.score(X_test, Y_test) / 3\n",
    "    avg_B = avg_B + bn.score(X_test, Y_test) / 3\n",
    "    avg_M = avg_M + multNB_clf.score(X_test, Y_test) / 3\n",
    "\n",
    "print(\"Gaussian: {}\".format(avg_G))\n",
    "print(\"Bernoulli: {}\".format(avg_B))\n",
    "print(\"Multinomial: {}\".format(avg_M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2F\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "kf = KFold(n_splits=3)\n",
    "avg_L = 0\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    X_train, X_test = train_data[train_index], train_data[test_index]\n",
    "    Y_train, Y_test = train_labels[train_index], train_labels[test_index]\n",
    "    LR.fit(X_train, Y_train)\n",
    "    avg_L = avg_L + LR.score(X_test, Y_test) / 3\n",
    "print(\"Logistic Regression: {}\".format(avg_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1G\n",
    "with open(\"test.json\", \"r\") as testfile:\n",
    "    test_json_data = json.load(testfile)\n",
    "test_data = []\n",
    "test_ids = []\n",
    "for data in test_json_data:\n",
    "    test_ids.append(d[\"id\"])\n",
    "    appears = [0] * len(unique_ingred)\n",
    "    for i in data[\"ingredients\"]:\n",
    "        if i in ing:\n",
    "            appears[ing[i]] = 1\n",
    "    test_data.append(appears)\n",
    "test_ids = np.array(test_ids)\n",
    "test_data = np.array(test_data)  \n",
    "\n",
    "multNB_clf.fit(train_data, train_labels)\n",
    "LR.fit(train_data, train_labels)\n",
    "\n",
    "naive_pred = multNB_clf.predict(test_data)\n",
    "log_pred = LR.predict(test_data)\n",
    "\n",
    "np.savetxt(\"Test_Ids.csv\", test_ids, delimiter=\",\")\n",
    "np.savetxt(\"logistic_pred.csv\", log_pred, delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"naive_bayes_pred.csv\", naive_pred, delimiter=\",\", fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
