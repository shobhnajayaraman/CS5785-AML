{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 \n",
    "Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = []\n",
    "for line in open('sentiment labelled sentences/yelp_labelled.txt'):\n",
    "    line = line.strip('\\n')\n",
    "    label = line[-1]\n",
    "    review = line[:-2]\n",
    "    yelp.append([review, int(label)])\n",
    "yelp = pd.DataFrame(yelp, columns = ['Review', 'Sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = []\n",
    "for line in open('sentiment labelled sentences/amazon_cells_labelled.txt'):\n",
    "    line = line.strip('\\n')\n",
    "    review = line[:-2]\n",
    "    label = line[-1]\n",
    "    amazon.append([review, int(label)])\n",
    "amazon = pd.DataFrame(amazon, columns = ['Review', 'Sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = []\n",
    "for line in open('sentiment labelled sentences/imdb_labelled.txt'):\n",
    "    line = line.strip('\\n')\n",
    "    review = line[:-2]\n",
    "    label = line[-1]\n",
    "    imdb.append([review, int(label)])\n",
    "imdb = pd.DataFrame(imdb, columns = ['Review', 'Sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio for yelp are  1.0\n",
      "ratio for amazon are  1.0\n",
      "ratio for imdb are  1.0\n"
     ]
    }
   ],
   "source": [
    "#review ratios\n",
    "r_yelp = (yelp.Sent == 1).sum()/ (len(yelp) - (yelp.Sent == 1).sum())\n",
    "print('ratio for yelp are ', r_yelp)\n",
    "\n",
    "r_amazon= (amazon.Sent == 1).sum()/ (len(amazon) - (amazon.Sent == 1).sum())\n",
    "print('ratio for amazon are ', r_amazon)\n",
    "\n",
    "r_imdb = (imdb.Sent == 1).sum()/ (len(imdb) - (imdb.Sent == 1).sum())\n",
    "print('ratio for imdb are ', r_imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are all balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk import *\n",
    "from nltk.stem.snowball import SnowballStemmer as SBS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we do lemmetization\n",
    "def lemmetize(s):\n",
    "    ps = SBS('english')\n",
    "    ls_stem = [ps.stem(word) for word in s.split()]\n",
    "    return ' '.join(ls_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv(s, ls):\n",
    "    return ' '.join(filter(lambda s: s not in ls, s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre procssing data\n",
    "def preprocess(df):\n",
    "    data = df\n",
    "    \n",
    "    # remove punctuation\n",
    "    punc = '[' + string.punctuation + ']'\n",
    "    data.Review = data.Review.apply(lambda x: re.sub(punc, '', x))\n",
    "    \n",
    "    # lowercase\n",
    "    data.Review = data.Review.apply(lambda x: x.lower())\n",
    "    \n",
    "    # remove stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    data.Review = data.Review.apply(lambda x: rmv(x, sw))\n",
    "      \n",
    "    # Lemmatization \n",
    "    data.Review = data.Review.apply(lambda x: lemmetize(x))\n",
    "    return data\n",
    "yelp = preprocess(yelp)\n",
    "amazon = preprocess(amazon)\n",
    "imdb = preprocess(imdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>wow love place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>crust good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tasti textur nasti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>select menu great price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sent\n",
       "0                                     wow love place     1\n",
       "1                                         crust good     0\n",
       "2                                 tasti textur nasti     0\n",
       "3  stop late may bank holiday rick steve recommen...     1\n",
       "4                            select menu great price     1"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason:\n",
    "\n",
    "Lowercase: Uppercase words and lowercase words are equivalent in a sentence.\n",
    "Lemmatization: The words such as sit, sitting and sat have similar meanings. It is easier to train a model if all words are lemmatized.\n",
    "Punctuations are removed because they are not that essential while training.\n",
    "I, we, them are stop words and they are redundant in sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customsplit(df):\n",
    "    df_1 = df[df.Sent == 1]\n",
    "    df_0 = df[df.Sent == 0]\n",
    "    train1 = df_1[:400]\n",
    "    test1 = df_1[400:]\n",
    "    train0 = df_0[:400]\n",
    "    test0 = df_0[400:]\n",
    "    return train1, test1, train0, test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train1, a_test1, a_train0, a_test0 = customsplit(amazon)\n",
    "y_train1, y_test1, y_train0, y_test0 = customsplit(yelp)\n",
    "i_train1, i_test1, i_train0, i_test0 = customsplit(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = [a_train1, a_train0, y_train1, y_train0, i_train1, i_train0]\n",
    "tests = [a_test1, a_test0, y_test1, y_test0, i_test1, i_test1]\n",
    "train = pd.concat(trains)\n",
    "test = pd.concat(tests)\n",
    "\n",
    "train.reset_index(inplace = True)\n",
    "train.drop('index',axis = 1, inplace = True)\n",
    "test.reset_index(inplace = True)\n",
    "test.drop('index',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 2), (600, 2))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  3629  unique words training set\n"
     ]
    }
   ],
   "source": [
    "my_dict = np.array(list(set(' '.join(train.Review).split())))\n",
    "print('There are ', len(my_dict), ' unique words training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't use test data at this point for creating dictionary because we need to use the training data to train the model and training data may not have all the words that test data has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag(s):\n",
    "    a = s.split()\n",
    "    v = np.sum([dic == w for w in a],axis=0)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['vector'] = train.Review.apply(bag)\n",
    "test['vector'] = test.Review.apply(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel bluetooth headset\n",
      "[0 0 0 ... 0 0 0]\n",
      "phone pretti sturdi ive never larg problem\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# picking any two reviews to report feature vectors\n",
    "for z in [20,25]:\n",
    "    print(train.Review[z])\n",
    "    print(train.vector[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log vector'] = train.vector.apply(lambda x: np.log(x+1))\n",
    "test['log vector'] = test.vector.apply(lambda x: np.log(x+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-Normalization to reduce the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(train['log vector'])\n",
    "y_train = train.Sent\n",
    "x_test = np.vstack(test['log vector'])\n",
    "y_test = test.Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l1',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1, param_grid={'C': [0.1, 0.5, 1, 5, 10, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras = {'C': [0.1, 0.5, 1, 5, 10, 50]}\n",
    "clf = GridSearchCV(lr(penalty = 'l1'), paras, cv = 5, n_jobs = -1, scoring = 'accuracy' )\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.815\n"
     ]
    }
   ],
   "source": [
    "lr_prediction = clf.predict(x_test)\n",
    "print('Accuracy: ', clf.best_estimator_.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[179,  21],\n",
       "       [ 90, 310]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test, lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['beauti', 'fantast', 'worst', 'amaz', 'excel', 'bad', 'delici',\n",
       "       'poor', 'love', 'great'], dtype='<U32')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = lr(penalty = 'l2', C = 5)\n",
    "l.fit(x_train, y_train)\n",
    "ind = abs(l.coef_)\n",
    "z = dic[np.argsort(ind)]\n",
    "z[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beauti', 'fantast', 'worst', 'amaz', 'excel', 'bad', 'delici',\n",
       "       'poor', 'love', 'great'], dtype='<U32')"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = dic[np.argsort(ind)]\n",
    "z[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.785\n"
     ]
    }
   ],
   "source": [
    "BNB_prediction = BNB.predict(x_test)\n",
    "print('Accuracy: ', BNB.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[168,  32],\n",
       "       [ 97, 303]])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test, BNB_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_gram(s):\n",
    "    s_s = s.split()\n",
    "    return [s_s[i] + ' ' + s_s[i+1] for i in range(len(s_s)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['two_gram'] = train.Review.apply(two_gram)\n",
    "test['two_gram'] = test.Review.apply(two_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "dic_w = np.array(list(set(itertools.chain(*train.two_gram))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-gram feature\n",
    "def two_g(s):\n",
    "    if s == []:\n",
    "        return np.array([0]*len(dic_w))\n",
    "    else:\n",
    "        v = np.sum([dic_w == w for w in s],axis=0)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['vector_2g'] = train.two_gram.apply(two_g)\n",
    "test['vector_2g'] = test.two_gram.apply(two_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['vector_2g_log'] = train.vector_2g.apply(lambda x: np.log(x+1))\n",
    "test['vector_2g_log'] = test.vector_2g.apply(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_l = np.vstack(train['vector_2g_log'])\n",
    "y_train_l = train.Sent\n",
    "x_test_l = np.vstack(test['vector_2g_log'])\n",
    "y_test_l = test.Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.5, 1, 2, 5, 10, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "paras = {'C': [0.1, 0.5, 1, 2, 5, 10, 50]}\n",
    "clf = GridSearchCV(lr(penalty='l2'), paras, cv = 5, n_jobs = -1)\n",
    "clf.fit(x_train_l, y_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.55\n"
     ]
    }
   ],
   "source": [
    "lr_prediction = clf.predict(x_test_l)\n",
    "print('Accuracy: ', clf.best_estimator_.score(x_test_l, y_test_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[176,  24],\n",
       "       [246, 154]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test_l, lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5483333333333333\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[179,  21],\n",
       "       [250, 150]])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(x_train_l, y_train_l)\n",
    "\n",
    "BNB_prediction = BNB.predict(x_test_l)\n",
    "print('Accuracy: ', BNB.score(x_test_l, y_test_l))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test_l, BNB_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 3629)\n"
     ]
    }
   ],
   "source": [
    "# feature matrix\n",
    "fm = np.vstack(train['log vector'])\n",
    "print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_m(df):\n",
    "    mean_vector = np.mean(df,axis=1).reshape(-1,1)\n",
    "\n",
    "# subtract mean\n",
    "    return df - mean_vector\n",
    "fm_sub_m = sub_m(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm(c):\n",
    "    m = c.T\n",
    "\n",
    "    num_f, num_o = m.shape\n",
    "\n",
    "#finding the mean vector\n",
    "    mean_vector = np.mean(m,axis=1).reshape(-1,1)\n",
    "#subtract mean : vector\n",
    "    fm_sub_m = m - mean_vector\n",
    "    \n",
    "    # find covariance \n",
    "    covariance_m = fm_sub_m.dot(fm_sub_m.T)/(num_o - 1)\n",
    "    \n",
    "    return covariance_m\n",
    "\n",
    "cm = get_cm(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnonalization\n",
    "def diagonalize(m):\n",
    "    \n",
    "    evalues, evectors = np.linalg.eigh(m)\n",
    "    idx = evalues.argsort()[::-1]\n",
    "    evalues = np.diag(evalues[idx])\n",
    "    evectors = evectors[:,idx]\n",
    "    \n",
    "    return evalues, evectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, P = diagonalize(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3629, 3629)"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#principal component analysis\n",
    "\n",
    "# dimensionality reduction\n",
    "x_train10 = fm_sub_m.dot(P[:,:10])\n",
    "x_train50 = fm_sub_m.dot(P[:,:50])\n",
    "x_train100 = fm_sub_m.dot(P[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dimensionality reduction for test data\n",
    "fm_test = np.vstack(test['log vector'])\n",
    "test_mean = np.mean(fm_test,axis=1).reshape(-1,1)\n",
    "    \n",
    "# subtract mean\n",
    "fm_test_sub_m = fm_test - test_mean\n",
    "\n",
    "x_test10 = fm_test_sub_m.dot(P[:,:10])\n",
    "x_test50 = fm_test_sub_m.dot(P[:,:50])\n",
    "x_test100 = fm_test_sub_m.dot(P[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.5483333333333333\n",
      "Confusion Matrix: \n",
      " [[174  26]\n",
      " [245 155]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 50:\n",
      "Accuracy:  0.675\n",
      "Confusion Matrix: \n",
      " [[170  30]\n",
      " [165 235]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.6966666666666667\n",
      "Confusion Matrix: \n",
      " [[158  42]\n",
      " [140 260]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50,100]:\n",
    "\n",
    "    exec('x_train_pc = x_train' + str(i))\n",
    "    exec('x_test_pc = x_test' + str(i))\n",
    "\n",
    "    paras = {'C': [0.1, 0.5, 1, 5, 10, 50]\n",
    "            }\n",
    "    clf = GridSearchCV(lr(penalty = 'l2'), paras, cv = 5, n_jobs = -1, scoring = 'accuracy' )\n",
    "    clf.fit(x_train_pc, y_train)\n",
    "\n",
    "    lr_prediction = clf.predict(x_test_pc)\n",
    "\n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', clf.best_estimator_.score(x_test_pc, y_test_l))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test_l, lr_prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.585\n",
      "Confusion Matrix: \n",
      " [[120  80]\n",
      " [169 231]]\n",
      "\n",
      "\n",
      "Performance with PC 50:\n",
      "Accuracy:  0.6083333333333333\n",
      "Confusion Matrix: \n",
      " [[129  71]\n",
      " [164 236]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.64\n",
      "Confusion Matrix: \n",
      " [[129  71]\n",
      " [145 255]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50, 100]:\n",
    "    \n",
    "    exec('x_train_pc = x_train' + str(i))\n",
    "    exec('x_test_pc = x_test' + str(i))\n",
    "    \n",
    "    BNB = BernoulliNB()\n",
    "    BNB.fit(x_train_pc, y_train)\n",
    "    BNB_prediction = BNB.predict(x_test_pc)\n",
    "    \n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', BNB.score(x_test_pc, y_test))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, BNB_prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix\n",
    "fm2 = np.vstack(train.vector_2g_log)\n",
    "\n",
    "fm2 = sub_m(fm2)\n",
    "\n",
    "# covariance matrix\n",
    "def get_cm(c):                  \n",
    "    m = c.T\n",
    "\n",
    "    num_f, num_o = m.shape\n",
    "\n",
    "    # find mean\n",
    "    mean_vector = np.mean(m,axis=1).reshape(-1,1)\n",
    "    \n",
    "    # subtract mean\n",
    "    fm_sub_m = m - mean_vector\n",
    "    \n",
    "    # find covariance \n",
    "    covariance_m = fm_sub_m.dot(fm_sub_m.T)/(num_o - 1)\n",
    "    \n",
    "    return covariance_m\n",
    "\n",
    "cm2 = get_cm(fm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnonalization\n",
    "def diagonalize(m):\n",
    "    \n",
    "    evalues, evectors = np.linalg.eigh(m)\n",
    "    idx = evalues.argsort()[::-1]\n",
    "    evalues = np.diag(evalues[idx])\n",
    "    evectors = evectors[:,idx]\n",
    "    \n",
    "    return evalues, evectors\n",
    "\n",
    "E2, P2 = diagonalize(cm2)\n",
    "\n",
    "\n",
    "#  dimensionality reduction\n",
    "x_2_train10 = fm2.dot(P2[:,:10])\n",
    "x_2_train50 = fm2.dot(P2[:,:50])\n",
    "x_2_train100 = fm2.dot(P2[:,:100])\n",
    "\n",
    "\n",
    "#  dimensionality reduction for test data\n",
    "fm2_test = np.vstack(test.vector_2g_log)\n",
    "fm2_test = sub_m(fm2_test)\n",
    "\n",
    "x_2_test10 = fm2_test.dot(P2[:,:10])\n",
    "x_2_test50 = fm2_test.dot(P2[:,:50])\n",
    "x_2_test100 = fm2_test.dot(P2[:,:100])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in [10, 50,100]:\n",
    "    \n",
    "    exec('x_2_train_pc = x_2_train' + str(i))\n",
    "    exec('x_2_test_pc = x_2_test' + str(i))\n",
    "\n",
    "    paras = {'C': [0.1, 0.5, 1, 5, 10, 50]}\n",
    "    clf = GridSearchCV(lr(penalty = 'l2'), paras, cv = 5, n_jobs = -1, scoring = 'accuracy' )\n",
    "    clf.fit(x_2_train_pc, y_train)\n",
    "\n",
    "    lr_prediction = clf.predict(x_2_test_pc)\n",
    "\n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', clf.best_estimator_.score(x_2_test_pc, y_test_l))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, lr_prediction))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.37166666666666665\n",
      "Confusion Matrix: \n",
      " [[194   6]\n",
      " [371  29]]\n",
      "\n",
      "\n",
      "Performance with PC 50:\n",
      "Accuracy:  0.4266666666666667\n",
      "Confusion Matrix: \n",
      " [[173  27]\n",
      " [317  83]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.5716666666666667\n",
      "Confusion Matrix: \n",
      " [[ 44 156]\n",
      " [101 299]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50, 100]:\n",
    "    \n",
    "    exec('x_2_train_pc = x_2_train' + str(i))\n",
    "    exec('x_2_test_pc = x_2_test' + str(i))\n",
    "    \n",
    "    BNB = BernoulliNB()\n",
    "    BNB.fit(x_2_train_pc, y_train)\n",
    "    BNB_prediction = BNB.predict(x_2_test_pc)\n",
    "    \n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', BNB.score(x_2_test_pc, y_test))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, BNB_prediction))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['beauti', 'fantast', 'worst', 'amaz', 'excel', 'bad', 'delici',\n",
       "       'poor', 'love', 'great'], dtype='<U32')"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.fit(x_train, y_train)\n",
    "ind = abs(l.coef_)\n",
    "z = dic[np.argsort(ind)]\n",
    "z[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['good price', 'realli good', 'easi use', 'food good',\n",
       "       'great product', 'one best', 'wast time', 'great phone',\n",
       "       'high recommend', 'work great'], dtype='<U39')"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = lr(penalty = 'l2', C = 5)\n",
    "l1.fit(x_train_l, y_train_l)\n",
    "ind = abs(l1.coef_)\n",
    "z1 = dic_w[np.argsort(ind)]\n",
    "z1[0][-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
